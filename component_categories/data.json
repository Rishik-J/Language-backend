{
  "SQLExecutor": {
    "template": {
      "_type": "CustomComponent",
      "add_error": {
        "type": "bool",
        "required": false,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": false,
        "value": false,
        "fileTypes": [],
        "file_path": "",
        "name": "add_error",
        "display_name": "Add Error",
        "advanced": false,
        "dynamic": false,
        "info": "Add the error to the result.",
        "load_from_db": false,
        "title_case": false
      },
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\nfrom langchain_community.utilities import SQLDatabase\n\nfrom langflow.custom import CustomComponent\nfrom langflow.field_typing import Text\n\n\nclass SQLExecutorComponent(CustomComponent):\n    display_name = \"SQL Query\"\n    description = \"Execute SQL query.\"\n    name = \"SQLExecutor\"\n    beta: bool = True\n\n    def build_config(self):\n        return {\n            \"database_url\": {\n                \"display_name\": \"Database URL\",\n                \"info\": \"The URL of the database.\",\n            },\n            \"include_columns\": {\n                \"display_name\": \"Include Columns\",\n                \"info\": \"Include columns in the result.\",\n            },\n            \"passthrough\": {\n                \"display_name\": \"Passthrough\",\n                \"info\": \"If an error occurs, return the query instead of raising an exception.\",\n            },\n            \"add_error\": {\n                \"display_name\": \"Add Error\",\n                \"info\": \"Add the error to the result.\",\n            },\n        }\n\n    def clean_up_uri(self, uri: str) -> str:\n        if uri.startswith(\"postgresql://\"):\n            uri = uri.replace(\"postgresql://\", \"postgres://\")\n        return uri.strip()\n\n    def build(\n        self,\n        query: str,\n        database_url: str,\n        *,\n        include_columns: bool = False,\n        passthrough: bool = False,\n        add_error: bool = False,\n        **kwargs,\n    ) -> Text:\n        _ = kwargs\n        error = None\n        try:\n            database = SQLDatabase.from_uri(database_url)\n        except Exception as e:\n            msg = f\"An error occurred while connecting to the database: {e}\"\n            raise ValueError(msg) from e\n        try:\n            tool = QuerySQLDataBaseTool(db=database)\n            result = tool.run(query, include_columns=include_columns)\n            self.status = result\n        except Exception as e:\n            result = str(e)\n            self.status = result\n            if not passthrough:\n                raise\n            error = repr(e)\n\n        if add_error and error is not None:\n            result = f\"{result}\\n\\nError: {error}\\n\\nQuery: {query}\"\n        elif error is not None:\n            # Then we won't add the error to the result\n            # but since we are in passthrough mode, we will return the query\n            result = query\n\n        return result\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "database_url": {
        "type": "str",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": false,
        "fileTypes": [],
        "file_path": "",
        "name": "database_url",
        "display_name": "Database URL",
        "advanced": false,
        "dynamic": false,
        "info": "The URL of the database.",
        "load_from_db": false,
        "title_case": false,
        "input_types": [
          "Text"
        ]
      },
      "include_columns": {
        "type": "bool",
        "required": false,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": false,
        "value": false,
        "fileTypes": [],
        "file_path": "",
        "name": "include_columns",
        "display_name": "Include Columns",
        "advanced": false,
        "dynamic": false,
        "info": "Include columns in the result.",
        "load_from_db": false,
        "title_case": false
      },
      "passthrough": {
        "type": "bool",
        "required": false,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": false,
        "value": false,
        "fileTypes": [],
        "file_path": "",
        "name": "passthrough",
        "display_name": "Passthrough",
        "advanced": false,
        "dynamic": false,
        "info": "If an error occurs, return the query instead of raising an exception.",
        "load_from_db": false,
        "title_case": false
      },
      "query": {
        "type": "str",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": false,
        "fileTypes": [],
        "file_path": "",
        "name": "query",
        "advanced": false,
        "dynamic": false,
        "info": "",
        "load_from_db": false,
        "title_case": false,
        "input_types": [
          "Text"
        ]
      }
    },
    "description": "Execute SQL query.",
    "base_classes": [
      "object",
      "str",
      "Text"
    ],
    "display_name": "SQL Query",
    "documentation": "",
    "minimized": false,
    "custom_fields": {
      "query": null,
      "database_url": null,
      "include_columns": null,
      "passthrough": null,
      "add_error": null
    },
    "output_types": [
      "Text"
    ],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Text"
        ],
        "selected": "Text",
        "name": "text",
        "hidden": null,
        "display_name": "Text",
        "method": null,
        "value": "__UNDEFINED__",
        "cache": true,
        "required_inputs": null,
        "allows_loop": false,
        "options": null,
        "tool_mode": true
      }
    ],
    "field_order": [],
    "beta": true,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "JSONtoData": {
    "template": {
      "_type": "Component",
      "json_file": {
        "trace_as_metadata": true,
        "file_path": "",
        "fileTypes": [
          "json"
        ],
        "temp_file": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "json_file",
        "value": "",
        "display_name": "JSON File",
        "advanced": false,
        "dynamic": false,
        "info": "Upload a JSON file to convert to a Data object or list of Data objects",
        "title_case": false,
        "type": "file",
        "_input_type": "FileInput"
      },
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "import json\nfrom pathlib import Path\n\nfrom json_repair import repair_json\n\nfrom langflow.custom import Component\nfrom langflow.io import FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema import Data\n\n\nclass JSONToDataComponent(Component):\n    display_name = \"Load JSON\"\n    description = (\n        \"Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects\"\n    )\n    icon = \"braces\"\n    name = \"JSONtoData\"\n    legacy = True\n\n    inputs = [\n        FileInput(\n            name=\"json_file\",\n            display_name=\"JSON File\",\n            file_types=[\"json\"],\n            info=\"Upload a JSON file to convert to a Data object or list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"json_path\",\n            display_name=\"JSON File Path\",\n            info=\"Provide the path to the JSON file as pure text\",\n        ),\n        MultilineInput(\n            name=\"json_string\",\n            display_name=\"JSON String\",\n            info=\"Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data\", display_name=\"Data\", method=\"convert_json_to_data\"),\n    ]\n\n    def convert_json_to_data(self) -> Data | list[Data]:\n        if sum(bool(field) for field in [self.json_file, self.json_path, self.json_string]) != 1:\n            msg = \"Please provide exactly one of: JSON file, file path, or JSON string.\"\n            self.status = msg\n            raise ValueError(msg)\n\n        json_data = None\n\n        try:\n            if self.json_file:\n                resolved_path = self.resolve_path(self.json_file)\n                file_path = Path(resolved_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            elif self.json_path:\n                file_path = Path(self.json_path)\n                if file_path.suffix.lower() != \".json\":\n                    self.status = \"The provided file must be a JSON file.\"\n                else:\n                    json_data = file_path.read_text(encoding=\"utf-8\")\n\n            else:\n                json_data = self.json_string\n\n            if json_data:\n                # Try to parse the JSON string\n                try:\n                    parsed_data = json.loads(json_data)\n                except json.JSONDecodeError:\n                    # If JSON parsing fails, try to repair the JSON string\n                    repaired_json_string = repair_json(json_data)\n                    parsed_data = json.loads(repaired_json_string)\n\n                # Check if the parsed data is a list\n                if isinstance(parsed_data, list):\n                    result = [Data(data=item) for item in parsed_data]\n                else:\n                    result = Data(data=parsed_data)\n                self.status = result\n                return result\n\n        except (json.JSONDecodeError, SyntaxError, ValueError) as e:\n            error_message = f\"Invalid JSON or Python literal: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        except Exception as e:\n            error_message = f\"An error occurred: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        # An error occurred\n        raise ValueError(self.status)\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "json_path": {
        "tool_mode": false,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "json_path",
        "value": "",
        "display_name": "JSON File Path",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Provide the path to the JSON file as pure text",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      },
      "json_string": {
        "tool_mode": false,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "json_string",
        "value": "",
        "display_name": "JSON String",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Enter a valid JSON string (object or array) to convert to a Data object or list of Data objects",
        "title_case": false,
        "copy_field": false,
        "type": "str",
        "_input_type": "MultilineInput"
      }
    },
    "description": "Convert a JSON file, JSON from a file path, or a JSON string to a Data object or a list of Data objects",
    "icon": "braces",
    "base_classes": [
      "Data"
    ],
    "display_name": "Load JSON",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data",
        "display_name": "Data",
        "method": "convert_json_to_data",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "json_file",
      "json_path",
      "json_string"
    ],
    "beta": false,
    "legacy": true,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "Webhook": {
    "template": {
      "_type": "Component",
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "import json\n\nfrom langflow.custom import Component\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema import Data\n\n\nclass WebhookComponent(Component):\n    display_name = \"Webhook\"\n    name = \"Webhook\"\n    icon = \"webhook\"\n\n    inputs = [\n        MultilineInput(\n            name=\"data\",\n            display_name=\"Payload\",\n            info=\"Receives a payload from external systems via HTTP POST.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"curl\",\n            display_name=\"cURL\",\n            value=\"CURL_WEBHOOK\",\n            advanced=True,\n            input_types=[],\n        ),\n        MultilineInput(\n            name=\"endpoint\",\n            display_name=\"Endpoint\",\n            value=\"BACKEND_URL\",\n            advanced=False,\n            copy_field=True,\n            input_types=[],\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Data\", name=\"output_data\", method=\"build_data\"),\n    ]\n\n    def build_data(self) -> Data:\n        message: str | Data = \"\"\n        if not self.data:\n            self.status = \"No data provided.\"\n            return Data(data={})\n        try:\n            body = json.loads(self.data or \"{}\")\n        except json.JSONDecodeError:\n            body = {\"payload\": self.data}\n            message = f\"Invalid JSON payload. Please check the format.\\n\\n{self.data}\"\n        data = Data(data=body)\n        if not message:\n            message = data\n        self.status = message\n        return data\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "curl": {
        "tool_mode": false,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "curl",
        "value": "CURL_WEBHOOK",
        "display_name": "cURL",
        "advanced": true,
        "input_types": [],
        "dynamic": false,
        "info": "",
        "title_case": false,
        "copy_field": false,
        "type": "str",
        "_input_type": "MultilineInput"
      },
      "data": {
        "tool_mode": false,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "data",
        "value": "",
        "display_name": "Payload",
        "advanced": true,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Receives a payload from external systems via HTTP POST.",
        "title_case": false,
        "copy_field": false,
        "type": "str",
        "_input_type": "MultilineInput"
      },
      "endpoint": {
        "tool_mode": false,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "endpoint",
        "value": "BACKEND_URL",
        "display_name": "Endpoint",
        "advanced": false,
        "input_types": [],
        "dynamic": false,
        "info": "",
        "title_case": false,
        "copy_field": true,
        "type": "str",
        "_input_type": "MultilineInput"
      }
    },
    "icon": "webhook",
    "base_classes": [
      "Data"
    ],
    "display_name": "Webhook",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "output_data",
        "display_name": "Data",
        "method": "build_data",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "data",
      "curl",
      "endpoint"
    ],
    "beta": false,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "APIRequest": {
    "template": {
      "_type": "Component",
      "query_params": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "trace_as_input": true,
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "query_params",
        "value": "",
        "display_name": "Query Parameters",
        "advanced": true,
        "input_types": [
          "Data"
        ],
        "dynamic": false,
        "info": "The query parameters to append to the URL.",
        "title_case": false,
        "type": "other",
        "_input_type": "DataInput"
      },
      "body": {
        "tool_mode": false,
        "is_list": true,
        "list_add_label": "Add More",
        "table_schema": {
          "columns": [
            {
              "name": "key",
              "display_name": "Key",
              "sortable": true,
              "filterable": true,
              "formatter": "text",
              "type": "str",
              "description": "Parameter name",
              "default": "None",
              "disable_edit": false,
              "edit_mode": "popover",
              "hidden": false
            },
            {
              "name": "value",
              "display_name": "Value",
              "sortable": true,
              "filterable": true,
              "description": "Parameter value",
              "default": "None",
              "disable_edit": false,
              "edit_mode": "popover",
              "hidden": false
            }
          ]
        },
        "trigger_text": "Open table",
        "trigger_icon": "Table",
        "table_icon": "Table",
        "trace_as_metadata": true,
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "body",
        "value": [],
        "display_name": "Body",
        "advanced": true,
        "input_types": [
          "Data"
        ],
        "dynamic": false,
        "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT).",
        "title_case": false,
        "type": "table",
        "_input_type": "TableInput"
      },
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "import asyncio\nimport json\nimport re\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport aiofiles\nimport aiofiles.os as aiofiles_os\nimport httpx\nimport validators\n\nfrom langflow.base.curl.parse import parse_context\nfrom langflow.custom import Component\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    FloatInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    StrInput,\n    TableInput,\n)\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.dotdict import dotdict\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = \"Make HTTP requests using URLs or cURL commands.\"\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    default_keys = [\"urls\", \"method\", \"query_params\"]\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            list=True,\n            info=\"Enter one or more URLs, separated by commas.\",\n            advanced=False,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"curl\",\n            display_name=\"cURL\",\n            info=(\n                \"Paste a curl command to populate the fields. \"\n                \"This will fill in the dictionary fields for headers and body.\"\n            ),\n            advanced=True,\n            real_time_refresh=True,\n            tool_mode=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\n            info=\"The HTTP method to use.\",\n            real_time_refresh=True,\n        ),\n        BoolInput(\n            name=\"use_curl\",\n            display_name=\"Use cURL\",\n            value=False,\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\n            real_time_refresh=True,\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Parameter name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"description\": \"Parameter value\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n            advanced=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request as a dictionary.\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[],\n            advanced=True,\n            input_types=[\"Data\"],\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=5,\n            info=\"The timeout to use for the request.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"follow_redirects\",\n            display_name=\"Follow Redirects\",\n            value=True,\n            info=\"Whether to follow http redirects.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"save_to_file\",\n            display_name=\"Save to File\",\n            value=False,\n            info=\"Save the API response to a temporary file\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_httpx_metadata\",\n            display_name=\"Include HTTPx Metadata\",\n            value=False,\n            info=(\n                \"Include properties such as headers, status_code, response_headers, \"\n                \"and redirection_history in the output.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"make_requests\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def _parse_json_value(self, value: Any) -> Any:\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\n        if not isinstance(value, str):\n            return value\n\n        try:\n            parsed = json.loads(value)\n        except json.JSONDecodeError:\n            return value\n        else:\n            return parsed\n\n    def _process_body(self, body: Any) -> dict:\n        \"\"\"Process the body input into a valid dictionary.\n\n        Args:\n            body: The body to process, can be dict, str, or list\n        Returns:\n            Processed dictionary\n        \"\"\"\n        if body is None:\n            return {}\n        if isinstance(body, dict):\n            return self._process_dict_body(body)\n        if isinstance(body, str):\n            return self._process_string_body(body)\n        if isinstance(body, list):\n            return self._process_list_body(body)\n\n        return {}\n\n    def _process_dict_body(self, body: dict) -> dict:\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\n        return {k: self._parse_json_value(v) for k, v in body.items()}\n\n    def _process_string_body(self, body: str) -> dict:\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\n        try:\n            return self._process_body(json.loads(body))\n        except json.JSONDecodeError:\n            return {\"data\": body}\n\n    def _process_list_body(self, body: list) -> dict:\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\n        processed_dict = {}\n\n        try:\n            for item in body:\n                if not self._is_valid_key_value_item(item):\n                    continue\n\n                key = item[\"key\"]\n                value = self._parse_json_value(item[\"value\"])\n                processed_dict[key] = value\n\n        except (KeyError, TypeError, ValueError) as e:\n            self.log(f\"Failed to process body list: {e}\")\n            return {}  # Return empty dictionary instead of None\n\n        return processed_dict\n\n    def _is_valid_key_value_item(self, item: Any) -> bool:\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        \"\"\"Parse a cURL command and update build configuration.\n\n        Args:\n            curl: The cURL command to parse\n            build_config: The build configuration to update\n        Returns:\n            Updated build configuration\n        \"\"\"\n        try:\n            parsed = parse_context(curl)\n\n            # Update basic configuration\n            build_config[\"urls\"][\"value\"] = [parsed.url]\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n            build_config[\"headers\"][\"advanced\"] = True\n            build_config[\"body\"][\"advanced\"] = True\n\n            # Process headers\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\n            build_config[\"headers\"][\"value\"] = headers_list\n\n            if headers_list:\n                build_config[\"headers\"][\"advanced\"] = False\n\n            # Process body data\n            if not parsed.data:\n                build_config[\"body\"][\"value\"] = []\n            elif parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    if isinstance(json_data, dict):\n                        body_list = [\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\n                            for k, v in json_data.items()\n                        ]\n                        build_config[\"body\"][\"value\"] = body_list\n                        build_config[\"body\"][\"advanced\"] = False\n                    else:\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\n                        build_config[\"body\"][\"advanced\"] = False\n                except json.JSONDecodeError:\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\n                    build_config[\"body\"][\"advanced\"] = False\n\n        except Exception as exc:\n            msg = f\"Error parsing curl: {exc}\"\n            self.log(msg)\n            raise ValueError(msg) from exc\n\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        if field_name == \"use_curl\":\n            build_config = self._update_curl_mode(build_config, use_curl=field_value)\n\n            # Fields that should not be reset\n            preserve_fields = {\"timeout\", \"follow_redirects\", \"save_to_file\", \"include_httpx_metadata\", \"use_curl\"}\n\n            # Mapping between input types and their reset values\n            type_reset_mapping = {\n                TableInput: [],\n                BoolInput: False,\n                IntInput: 0,\n                FloatInput: 0.0,\n                MessageTextInput: \"\",\n                StrInput: \"\",\n                MultilineInput: \"\",\n                DropdownInput: \"GET\",\n                DataInput: {},\n            }\n\n            for input_field in self.inputs:\n                # Only reset if field is not in preserve list\n                if input_field.name not in preserve_fields:\n                    reset_value = type_reset_mapping.get(type(input_field), None)\n                    build_config[input_field.name][\"value\"] = reset_value\n                    self.log(f\"Reset field {input_field.name} to {reset_value}\")\n        elif field_name == \"method\" and not self.use_curl:\n            build_config = self._update_method_fields(build_config, field_value)\n        elif field_name == \"curl\" and self.use_curl and field_value:\n            build_config = self.parse_curl(field_value, build_config)\n        return build_config\n\n    def _update_curl_mode(self, build_config: dotdict, *, use_curl: bool) -> dotdict:\n        always_visible = [\"method\", \"use_curl\"]\n\n        for field in self.inputs:\n            field_name = field.name\n            field_config = build_config.get(field_name)\n            if isinstance(field_config, dict):\n                if field_name in always_visible:\n                    field_config[\"advanced\"] = False\n                elif field_name == \"urls\":\n                    field_config[\"advanced\"] = use_curl\n                elif field_name == \"curl\":\n                    field_config[\"advanced\"] = not use_curl\n                    field_config[\"real_time_refresh\"] = use_curl\n                elif field_name in {\"body\", \"headers\"}:\n                    field_config[\"advanced\"] = True  # Always keep body and headers in advanced when use_curl is False\n                else:\n                    field_config[\"advanced\"] = use_curl\n            else:\n                self.log(f\"Expected dict for build_config[{field_name}], got {type(field_config).__name__}\")\n\n        if not use_curl:\n            current_method = build_config.get(\"method\", {}).get(\"value\", \"GET\")\n            build_config = self._update_method_fields(build_config, current_method)\n\n        return build_config\n\n    def _update_method_fields(self, build_config: dotdict, method: str) -> dotdict:\n        common_fields = [\n            \"urls\",\n            \"method\",\n            \"use_curl\",\n        ]\n\n        always_advanced_fields = [\n            \"body\",\n            \"headers\",\n            \"timeout\",\n            \"follow_redirects\",\n            \"save_to_file\",\n            \"include_httpx_metadata\",\n        ]\n\n        body_fields = [\"body\"]\n\n        for field in self.inputs:\n            field_name = field.name\n            field_config = build_config.get(field_name)\n            if isinstance(field_config, dict):\n                if field_name in common_fields:\n                    field_config[\"advanced\"] = False\n                elif field_name in body_fields:\n                    field_config[\"advanced\"] = method not in {\"POST\", \"PUT\", \"PATCH\"}\n                elif field_name in always_advanced_fields:\n                    field_config[\"advanced\"] = True\n                else:\n                    field_config[\"advanced\"] = True\n            else:\n                self.log(f\"Expected dict for build_config[{field_name}], got {type(field_config).__name__}\")\n\n        return build_config\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: dict | None = None,\n        body: Any = None,\n        timeout: int = 5,\n        *,\n        follow_redirects: bool = True,\n        save_to_file: bool = False,\n        include_httpx_metadata: bool = False,\n    ) -> Data:\n        method = method.upper()\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\n            msg = f\"Unsupported method: {method}\"\n            raise ValueError(msg)\n\n        # Process body using the new helper method\n        processed_body = self._process_body(body)\n        redirection_history = []\n\n        try:\n            response = await client.request(\n                method,\n                url,\n                headers=headers,\n                json=processed_body,\n                timeout=timeout,\n                follow_redirects=follow_redirects,\n            )\n\n            redirection_history = [\n                {\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\n                    \"status_code\": redirect.status_code,\n                }\n                for redirect in response.history\n            ]\n\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\n            response_headers = self._headers_to_dict(response.headers)\n\n            metadata: dict[str, Any] = {\n                \"source\": url,\n            }\n\n            if save_to_file:\n                mode = \"wb\" if is_binary else \"w\"\n                encoding = response.encoding if mode == \"w\" else None\n                if file_path:\n                    # Ensure parent directory exists\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\n                    if is_binary:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            await f.write(response.content)\n                            await f.flush()\n                    else:\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\n                            await f.write(response.text)\n                            await f.flush()\n                    metadata[\"file_path\"] = str(file_path)\n\n                if include_httpx_metadata:\n                    metadata.update(\n                        {\n                            \"headers\": headers,\n                            \"status_code\": response.status_code,\n                            \"response_headers\": response_headers,\n                            **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                        }\n                    )\n                return Data(data=metadata)\n\n            if is_binary:\n                result = response.content\n            else:\n                try:\n                    result = response.json()\n                except json.JSONDecodeError:\n                    self.log(\"Failed to decode JSON response\")\n                    result = response.text.encode(\"utf-8\")\n\n            metadata.update({\"result\": result})\n\n            if include_httpx_metadata:\n                metadata.update(\n                    {\n                        \"headers\": headers,\n                        \"status_code\": response.status_code,\n                        \"response_headers\": response_headers,\n                        **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                    }\n                )\n            return Data(data=metadata)\n        except httpx.TimeoutException:\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 408,\n                    \"error\": \"Request timed out\",\n                },\n            )\n        except Exception as exc:  # noqa: BLE001\n            self.log(f\"Error making request to {url}\")\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    async def make_requests(self) -> list[Data]:\n        method = self.method\n        urls = [url.strip() for url in self.urls if url.strip()]\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        follow_redirects = self.follow_redirects\n        save_to_file = self.save_to_file\n        include_httpx_metadata = self.include_httpx_metadata\n\n        if self.use_curl and self.curl:\n            self._build_config = self.parse_curl(self.curl, dotdict())\n\n        invalid_urls = [url for url in urls if not validators.url(url)]\n        if invalid_urls:\n            msg = f\"Invalid URLs provided: {invalid_urls}\"\n            raise ValueError(msg)\n\n        if isinstance(self.query_params, str):\n            query_params = dict(parse_qsl(self.query_params))\n        else:\n            query_params = self.query_params.data if self.query_params else {}\n\n        # Process headers here\n        headers = self._process_headers(headers)\n\n        # Process body\n        body = self._process_body(body)\n\n        bodies = [body] * len(urls)\n\n        urls = [self.add_query_params(url, query_params) for url in urls]\n\n        async with httpx.AsyncClient() as client:\n            results = await asyncio.gather(\n                *[\n                    self.make_request(\n                        client,\n                        method,\n                        u,\n                        headers,\n                        rec,\n                        timeout,\n                        follow_redirects=follow_redirects,\n                        save_to_file=save_to_file,\n                        include_httpx_metadata=include_httpx_metadata,\n                    )\n                    for u, rec in zip(urls, bodies, strict=False)\n                ]\n            )\n        self.status = results\n        return results\n\n    async def _response_info(\n        self, response: httpx.Response, *, with_file_path: bool = False\n    ) -> tuple[bool, Path | None]:\n        \"\"\"Determine the file path and whether the response content is binary.\n\n        Args:\n            response (Response): The HTTP response object.\n            with_file_path (bool): Whether to save the response content to a file.\n\n        Returns:\n            Tuple[bool, Path | None]:\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\n        \"\"\"\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\n\n        if not with_file_path:\n            return is_binary, None\n\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\n\n        # Create directory asynchronously\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\n\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            content_disposition = response.headers[\"Content-Disposition\"]\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\n            if filename_match:\n                extracted_filename = filename_match.group(1)\n                filename = extracted_filename\n\n        # Step 3: Infer file extension or use part of the request URL if no filename\n        if not filename:\n            # Extract the last segment of the URL path\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\n            base_name = Path(url_path).name  # Get the last segment of the path\n            if not base_name:  # If the path ends with a slash or is empty\n                base_name = \"response\"\n\n            # Infer file extension\n            content_type_to_extension = {\n                \"text/plain\": \".txt\",\n                \"application/json\": \".json\",\n                \"image/jpeg\": \".jpg\",\n                \"image/png\": \".png\",\n                \"application/octet-stream\": \".bin\",\n            }\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\n            filename = f\"{base_name}{extension}\"\n\n        # Step 4: Define the full file path\n        file_path = component_temp_dir / filename\n\n        # Step 5: Check if file exists asynchronously and handle accordingly\n        try:\n            # Try to create the file exclusively (x mode) to check existence\n            async with aiofiles.open(file_path, \"x\") as _:\n                pass  # File created successfully, we can use this path\n        except FileExistsError:\n            # If file exists, append a timestamp to the filename\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\n\n        return is_binary, file_path\n\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\n        return {k.lower(): v for k, v in headers.items()}\n\n    def _process_headers(self, headers: Any) -> dict:\n        \"\"\"Process the headers input into a valid dictionary.\n\n        Args:\n            headers: The headers to process, can be dict, str, or list\n        Returns:\n            Processed dictionary\n        \"\"\"\n        if headers is None:\n            return {}\n        if isinstance(headers, dict):\n            return headers\n        if isinstance(headers, list):\n            processed_headers = {}\n            try:\n                for item in headers:\n                    if not self._is_valid_key_value_item(item):\n                        continue\n                    key = item[\"key\"]\n                    value = item[\"value\"]\n                    processed_headers[key] = value\n            except (KeyError, TypeError, ValueError) as e:\n                self.log(f\"Failed to process headers list: {e}\")\n                return {}  # Return empty dictionary instead of None\n            return processed_headers\n        return {}\n\n    async def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the API response data into a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the API response data.\n        \"\"\"\n        data = await self.make_requests()\n        return DataFrame(data)\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "curl": {
        "tool_mode": true,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "curl",
        "value": "",
        "display_name": "cURL",
        "advanced": true,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
        "real_time_refresh": true,
        "title_case": false,
        "copy_field": false,
        "type": "str",
        "_input_type": "MultilineInput"
      },
      "follow_redirects": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "follow_redirects",
        "value": true,
        "display_name": "Follow Redirects",
        "advanced": true,
        "dynamic": false,
        "info": "Whether to follow http redirects.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "headers": {
        "tool_mode": false,
        "is_list": true,
        "list_add_label": "Add More",
        "table_schema": {
          "columns": [
            {
              "name": "key",
              "display_name": "Header",
              "sortable": true,
              "filterable": true,
              "formatter": "text",
              "type": "str",
              "description": "Header name",
              "default": "None",
              "disable_edit": false,
              "edit_mode": "popover",
              "hidden": false
            },
            {
              "name": "value",
              "display_name": "Value",
              "sortable": true,
              "filterable": true,
              "formatter": "text",
              "type": "str",
              "description": "Header value",
              "default": "None",
              "disable_edit": false,
              "edit_mode": "popover",
              "hidden": false
            }
          ]
        },
        "trigger_text": "Open table",
        "trigger_icon": "Table",
        "table_icon": "Table",
        "trace_as_metadata": true,
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "headers",
        "value": [],
        "display_name": "Headers",
        "advanced": true,
        "input_types": [
          "Data"
        ],
        "dynamic": false,
        "info": "The headers to send with the request as a dictionary.",
        "title_case": false,
        "type": "table",
        "_input_type": "TableInput"
      },
      "include_httpx_metadata": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "include_httpx_metadata",
        "value": false,
        "display_name": "Include HTTPx Metadata",
        "advanced": true,
        "dynamic": false,
        "info": "Include properties such as headers, status_code, response_headers, and redirection_history in the output.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "method": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "options": [
          "GET",
          "POST",
          "PATCH",
          "PUT",
          "DELETE"
        ],
        "options_metadata": [],
        "combobox": false,
        "dialog_inputs": {},
        "toggle": false,
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "method",
        "value": "",
        "display_name": "Method",
        "advanced": false,
        "dynamic": false,
        "info": "The HTTP method to use.",
        "real_time_refresh": true,
        "title_case": false,
        "type": "str",
        "_input_type": "DropdownInput"
      },
      "save_to_file": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "save_to_file",
        "value": false,
        "display_name": "Save to File",
        "advanced": true,
        "dynamic": false,
        "info": "Save the API response to a temporary file",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "timeout": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "timeout",
        "value": 5,
        "display_name": "Timeout",
        "advanced": true,
        "dynamic": false,
        "info": "The timeout to use for the request.",
        "title_case": false,
        "type": "int",
        "_input_type": "IntInput"
      },
      "urls": {
        "tool_mode": true,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": true,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "urls",
        "value": "",
        "display_name": "URLs",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Enter one or more URLs, separated by commas.",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      },
      "use_curl": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "use_curl",
        "value": false,
        "display_name": "Use cURL",
        "advanced": false,
        "dynamic": false,
        "info": "Enable cURL mode to populate fields from a cURL command.",
        "real_time_refresh": true,
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      }
    },
    "description": "Make HTTP requests using URLs or cURL commands.",
    "icon": "Globe",
    "base_classes": [
      "Data",
      "DataFrame"
    ],
    "display_name": "API Request",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data",
        "display_name": "Data",
        "method": "make_requests",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "DataFrame"
        ],
        "selected": "DataFrame",
        "name": "dataframe",
        "display_name": "DataFrame",
        "method": "as_dataframe",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "urls",
      "curl",
      "method",
      "use_curl",
      "query_params",
      "body",
      "headers",
      "timeout",
      "follow_redirects",
      "save_to_file",
      "include_httpx_metadata"
    ],
    "beta": false,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "URLComponent": {
    "template": {
      "_type": "Component",
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "import logging\nimport re\n\nfrom bs4 import BeautifulSoup\nfrom langchain_community.document_loaders import RecursiveUrlLoader\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageTextInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\n\nlogger = logging.getLogger(__name__)\n\n\nclass URLComponent(Component):\n    \"\"\"A component that loads and parses child links from a root URL recursively.\"\"\"\n\n    display_name = \"URL\"\n    description = \"Load and parse child links from a root URL recursively\"\n    icon = \"layout-template\"\n    name = \"URLComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"urls\",\n            display_name=\"URLs\",\n            info=\"Enter one or more URLs to crawl recursively, by clicking the '+' button.\",\n            is_list=True,\n            tool_mode=True,\n            placeholder=\"Enter a URL...\",\n            list_add_label=\"Add URL\",\n        ),\n        IntInput(\n            name=\"max_depth\",\n            display_name=\"Max Depth\",\n            info=(\n                \"Controls how many 'clicks' away from the initial page the crawler will go:\\n\"\n                \"- depth 1: only the initial page\\n\"\n                \"- depth 2: initial page + all pages linked directly from it\\n\"\n                \"- depth 3: initial page + direct links + links found on those direct link pages\\n\"\n                \"Note: This is about link traversal, not URL path depth.\"\n            ),\n            value=1,\n            required=False,\n        ),\n        BoolInput(\n            name=\"prevent_outside\",\n            display_name=\"Prevent Outside\",\n            info=(\n                \"If enabled, only crawls URLs within the same domain as the root URL. \"\n                \"This helps prevent the crawler from going to external websites.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"use_async\",\n            display_name=\"Use Async\",\n            info=(\n                \"If enabled, uses asynchronous loading which can be significantly faster \"\n                \"but might use more system resources.\"\n            ),\n            value=True,\n            required=False,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"format\",\n            display_name=\"Output Format\",\n            info=\"Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.\",\n            options=[\"Text\", \"HTML\"],\n            value=\"Text\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"fetch_content\"),\n        Output(display_name=\"Message\", name=\"text\", method=\"fetch_content_text\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def validate_url(self, string: str) -> bool:\n        \"\"\"Validates if the given string matches URL pattern.\"\"\"\n        url_regex = re.compile(\n            r\"^(https?:\\/\\/)?\" r\"(www\\.)?\" r\"([a-zA-Z0-9.-]+)\" r\"(\\.[a-zA-Z]{2,})?\" r\"(:\\d+)?\" r\"(\\/[^\\s]*)?$\",\n            re.IGNORECASE,\n        )\n        return bool(url_regex.match(string))\n\n    def ensure_url(self, url: str) -> str:\n        \"\"\"Ensures the given string is a valid URL.\"\"\"\n        if not url.startswith((\"http://\", \"https://\")):\n            url = \"http://\" + url\n\n        if not self.validate_url(url):\n            error_msg = \"Invalid URL - \" + url\n            raise ValueError(error_msg)\n\n        return url\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Load documents from the URLs.\"\"\"\n        all_docs = []\n        data = []\n        try:\n            urls = list({self.ensure_url(url.strip()) for url in self.urls if url.strip()})\n\n            no_urls_msg = \"No valid URLs provided.\"\n            if not urls:\n                raise ValueError(no_urls_msg)\n\n            for processed_url in urls:\n                msg = f\"Loading documents from {processed_url}\"\n                logger.info(msg)\n\n                extractor = (lambda x: x) if self.format == \"HTML\" else (lambda x: BeautifulSoup(x, \"lxml\").get_text())\n                loader = RecursiveUrlLoader(\n                    url=processed_url,\n                    max_depth=self.max_depth,\n                    prevent_outside=self.prevent_outside,\n                    use_async=self.use_async,\n                    extractor=extractor,\n                )\n\n                docs = loader.load()\n                msg = f\"Found {len(docs)} documents from {processed_url}\"\n                logger.info(msg)\n                all_docs.extend(docs)\n\n            data = [Data(text=doc.page_content, **doc.metadata) for doc in all_docs]\n            self.status = data\n\n        except Exception as e:\n            msg = f\"Error loading documents: {e!s}\"\n            logger.exception(msg)\n            raise ValueError(msg) from e\n\n        self.status = data\n        return data\n\n    def fetch_content_text(self) -> Message:\n        \"\"\"Load documents and return their text content.\"\"\"\n        data = self.fetch_content()\n        result_string = data_to_text(\"{text}\", data)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def as_dataframe(self) -> DataFrame:\n        \"\"\"Convert the documents to a DataFrame.\"\"\"\n        data_frame = DataFrame(self.fetch_content())\n        self.status = data_frame\n        return data_frame\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "format": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "options": [
          "Text",
          "HTML"
        ],
        "options_metadata": [],
        "combobox": false,
        "dialog_inputs": {},
        "toggle": false,
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "format",
        "value": "Text",
        "display_name": "Output Format",
        "advanced": true,
        "dynamic": false,
        "info": "Output Format. Use 'Text' to extract the text from the HTML or 'HTML' for the raw HTML content.",
        "title_case": false,
        "type": "str",
        "_input_type": "DropdownInput"
      },
      "max_depth": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "max_depth",
        "value": 1,
        "display_name": "Max Depth",
        "advanced": false,
        "dynamic": false,
        "info": "Controls how many 'clicks' away from the initial page the crawler will go:\n- depth 1: only the initial page\n- depth 2: initial page + all pages linked directly from it\n- depth 3: initial page + direct links + links found on those direct link pages\nNote: This is about link traversal, not URL path depth.",
        "title_case": false,
        "type": "int",
        "_input_type": "IntInput"
      },
      "prevent_outside": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "prevent_outside",
        "value": true,
        "display_name": "Prevent Outside",
        "advanced": true,
        "dynamic": false,
        "info": "If enabled, only crawls URLs within the same domain as the root URL. This helps prevent the crawler from going to external websites.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "urls": {
        "tool_mode": true,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": true,
        "list_add_label": "Add URL",
        "required": false,
        "placeholder": "Enter a URL...",
        "show": true,
        "name": "urls",
        "value": "",
        "display_name": "URLs",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Enter one or more URLs to crawl recursively, by clicking the '+' button.",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      },
      "use_async": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "use_async",
        "value": true,
        "display_name": "Use Async",
        "advanced": true,
        "dynamic": false,
        "info": "If enabled, uses asynchronous loading which can be significantly faster but might use more system resources.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      }
    },
    "description": "Load and parse child links from a root URL recursively",
    "icon": "layout-template",
    "base_classes": [
      "Data",
      "DataFrame",
      "Message"
    ],
    "display_name": "URL",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data",
        "display_name": "Data",
        "method": "fetch_content",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "Message"
        ],
        "selected": "Message",
        "name": "text",
        "display_name": "Message",
        "method": "fetch_content_text",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "DataFrame"
        ],
        "selected": "DataFrame",
        "name": "dataframe",
        "display_name": "DataFrame",
        "method": "as_dataframe",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "urls",
      "max_depth",
      "prevent_outside",
      "use_async",
      "format"
    ],
    "beta": false,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "File": {
    "template": {
      "_type": "Component",
      "file_path": {
        "trace_as_metadata": true,
        "list": true,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "file_path",
        "value": "",
        "display_name": "Server File Path",
        "advanced": true,
        "input_types": [
          "Data",
          "Message"
        ],
        "dynamic": false,
        "info": "Data object with a 'file_path' property pointing to server file or a Message object with a path to the file. Supercedes 'Path' but supports same file types.",
        "title_case": false,
        "type": "other",
        "_input_type": "HandleInput"
      },
      "path": {
        "trace_as_metadata": true,
        "file_path": "",
        "fileTypes": [
          "txt",
          "md",
          "mdx",
          "csv",
          "json",
          "yaml",
          "yml",
          "xml",
          "html",
          "htm",
          "pdf",
          "docx",
          "py",
          "sh",
          "sql",
          "js",
          "ts",
          "tsx",
          "zip",
          "tar",
          "tgz",
          "bz2",
          "gz"
        ],
        "temp_file": false,
        "list": true,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "path",
        "value": [],
        "display_name": "Files",
        "advanced": false,
        "dynamic": false,
        "info": "Supported file extensions: txt, md, mdx, csv, json, yaml, yml, xml, html, htm, pdf, docx, py, sh, sql, js, ts, tsx; optionally bundled in file extensions: zip, tar, tgz, bz2, gz",
        "title_case": false,
        "type": "file",
        "_input_type": "FileInput"
      },
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "from langflow.base.data import BaseFileComponent\nfrom langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data\nfrom langflow.io import BoolInput, IntInput\nfrom langflow.schema import Data\n\n\nclass FileComponent(BaseFileComponent):\n    \"\"\"Handles loading and processing of individual or zipped text files.\n\n    This component supports processing multiple valid files within a zip archive,\n    resolving paths, validating file types, and optionally using multithreading for processing.\n    \"\"\"\n\n    display_name = \"File\"\n    description = \"Load a file to be used in your project.\"\n    icon = \"file-text\"\n    name = \"File\"\n\n    VALID_EXTENSIONS = TEXT_FILE_TYPES\n\n    inputs = [\n        *BaseFileComponent._base_inputs,\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"[Deprecated] Use Multithreading\",\n            advanced=True,\n            value=True,\n            info=\"Set 'Processing Concurrency' greater than 1 to enable multithreading.\",\n        ),\n        IntInput(\n            name=\"concurrency_multithreading\",\n            display_name=\"Processing Concurrency\",\n            advanced=True,\n            info=\"When multiple files are being processed, the number of files to process concurrently.\",\n            value=1,\n        ),\n    ]\n\n    outputs = [\n        *BaseFileComponent._base_outputs,\n    ]\n\n    def process_files(self, file_list: list[BaseFileComponent.BaseFile]) -> list[BaseFileComponent.BaseFile]:\n        \"\"\"Processes files either sequentially or in parallel, depending on concurrency settings.\n\n        Args:\n            file_list (list[BaseFileComponent.BaseFile]): List of files to process.\n\n        Returns:\n            list[BaseFileComponent.BaseFile]: Updated list of files with merged data.\n        \"\"\"\n\n        def process_file(file_path: str, *, silent_errors: bool = False) -> Data | None:\n            \"\"\"Processes a single file and returns its Data object.\"\"\"\n            try:\n                return parse_text_file_to_data(file_path, silent_errors=silent_errors)\n            except FileNotFoundError as e:\n                msg = f\"File not found: {file_path}. Error: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n            except Exception as e:\n                msg = f\"Unexpected error processing {file_path}: {e}\"\n                self.log(msg)\n                if not silent_errors:\n                    raise\n                return None\n\n        if not file_list:\n            msg = \"No files to process.\"\n            raise ValueError(msg)\n\n        concurrency = 1 if not self.use_multithreading else max(1, self.concurrency_multithreading)\n        file_count = len(file_list)\n\n        parallel_processing_threshold = 2\n        if concurrency < parallel_processing_threshold or file_count < parallel_processing_threshold:\n            if file_count > 1:\n                self.log(f\"Processing {file_count} files sequentially.\")\n            processed_data = [process_file(str(file.path), silent_errors=self.silent_errors) for file in file_list]\n        else:\n            self.log(f\"Starting parallel processing of {file_count} files with concurrency: {concurrency}.\")\n            file_paths = [str(file.path) for file in file_list]\n            processed_data = parallel_load_data(\n                file_paths,\n                silent_errors=self.silent_errors,\n                load_function=process_file,\n                max_concurrency=concurrency,\n            )\n\n        # Use rollup_basefile_data to merge processed data with BaseFile objects\n        return self.rollup_data(file_list, processed_data)\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "concurrency_multithreading": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "concurrency_multithreading",
        "value": 1,
        "display_name": "Processing Concurrency",
        "advanced": true,
        "dynamic": false,
        "info": "When multiple files are being processed, the number of files to process concurrently.",
        "title_case": false,
        "type": "int",
        "_input_type": "IntInput"
      },
      "delete_server_file_after_processing": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "delete_server_file_after_processing",
        "value": true,
        "display_name": "Delete Server File After Processing",
        "advanced": true,
        "dynamic": false,
        "info": "If true, the Server File Path will be deleted after processing.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "ignore_unspecified_files": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "ignore_unspecified_files",
        "value": false,
        "display_name": "Ignore Unspecified Files",
        "advanced": true,
        "dynamic": false,
        "info": "If true, Data with no 'file_path' property will be ignored.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "ignore_unsupported_extensions": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "ignore_unsupported_extensions",
        "value": true,
        "display_name": "Ignore Unsupported Extensions",
        "advanced": true,
        "dynamic": false,
        "info": "If true, files with unsupported extensions will not be processed.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "separator": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "separator",
        "value": "\n\n",
        "display_name": "Separator",
        "advanced": true,
        "dynamic": false,
        "info": "Specify the separator to use between multiple outputs in Message format.",
        "title_case": false,
        "type": "str",
        "_input_type": "StrInput"
      },
      "silent_errors": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "silent_errors",
        "value": false,
        "display_name": "Silent Errors",
        "advanced": true,
        "dynamic": false,
        "info": "If true, errors will not raise an exception.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "use_multithreading": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "use_multithreading",
        "value": true,
        "display_name": "[Deprecated] Use Multithreading",
        "advanced": true,
        "dynamic": false,
        "info": "Set 'Processing Concurrency' greater than 1 to enable multithreading.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      }
    },
    "description": "Load a file to be used in your project.",
    "icon": "file-text",
    "base_classes": [
      "Data",
      "DataFrame",
      "Message"
    ],
    "display_name": "File",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data",
        "display_name": "Data",
        "method": "load_files",
        "value": "__UNDEFINED__",
        "cache": true,
        "required_inputs": [],
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "DataFrame"
        ],
        "selected": "DataFrame",
        "name": "dataframe",
        "display_name": "DataFrame",
        "method": "load_dataframe",
        "value": "__UNDEFINED__",
        "cache": true,
        "required_inputs": [],
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "Message"
        ],
        "selected": "Message",
        "name": "message",
        "display_name": "Message",
        "method": "load_message",
        "value": "__UNDEFINED__",
        "cache": true,
        "required_inputs": [],
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "path",
      "file_path",
      "separator",
      "silent_errors",
      "delete_server_file_after_processing",
      "ignore_unsupported_extensions",
      "ignore_unspecified_files",
      "use_multithreading",
      "concurrency_multithreading"
    ],
    "beta": false,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "Directory": {
    "template": {
      "_type": "Component",
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "from langflow.base.data.utils import TEXT_FILE_TYPES, parallel_load_data, parse_text_file_to_data, retrieve_file_paths\nfrom langflow.custom import Component\nfrom langflow.io import BoolInput, IntInput, MessageTextInput, MultiselectInput\nfrom langflow.schema import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template import Output\n\n\nclass DirectoryComponent(Component):\n    display_name = \"Directory\"\n    description = \"Recursively load files from a directory.\"\n    icon = \"folder\"\n    name = \"Directory\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"path\",\n            display_name=\"Path\",\n            info=\"Path to the directory to load files from. Defaults to current directory ('.')\",\n            value=\".\",\n            tool_mode=True,\n        ),\n        MultiselectInput(\n            name=\"types\",\n            display_name=\"File Types\",\n            info=\"File types to load. Select one or more types or leave empty to load all supported types.\",\n            options=TEXT_FILE_TYPES,\n            value=[],\n        ),\n        IntInput(\n            name=\"depth\",\n            display_name=\"Depth\",\n            info=\"Depth to search for files.\",\n            value=0,\n        ),\n        IntInput(\n            name=\"max_concurrency\",\n            display_name=\"Max Concurrency\",\n            advanced=True,\n            info=\"Maximum concurrency for loading files.\",\n            value=2,\n        ),\n        BoolInput(\n            name=\"load_hidden\",\n            display_name=\"Load Hidden\",\n            advanced=True,\n            info=\"If true, hidden files will be loaded.\",\n        ),\n        BoolInput(\n            name=\"recursive\",\n            display_name=\"Recursive\",\n            advanced=True,\n            info=\"If true, the search will be recursive.\",\n        ),\n        BoolInput(\n            name=\"silent_errors\",\n            display_name=\"Silent Errors\",\n            advanced=True,\n            info=\"If true, errors will not raise an exception.\",\n        ),\n        BoolInput(\n            name=\"use_multithreading\",\n            display_name=\"Use Multithreading\",\n            advanced=True,\n            info=\"If true, multithreading will be used.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"load_directory\"),\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"as_dataframe\"),\n    ]\n\n    def load_directory(self) -> list[Data]:\n        path = self.path\n        types = self.types\n        depth = self.depth\n        max_concurrency = self.max_concurrency\n        load_hidden = self.load_hidden\n        recursive = self.recursive\n        silent_errors = self.silent_errors\n        use_multithreading = self.use_multithreading\n\n        resolved_path = self.resolve_path(path)\n\n        # If no types are specified, use all supported types\n        if not types:\n            types = TEXT_FILE_TYPES\n\n        # Check if all specified types are valid\n        invalid_types = [t for t in types if t not in TEXT_FILE_TYPES]\n        if invalid_types:\n            msg = f\"Invalid file types specified: {invalid_types}. Valid types are: {TEXT_FILE_TYPES}\"\n            raise ValueError(msg)\n\n        valid_types = types\n\n        file_paths = retrieve_file_paths(\n            resolved_path, load_hidden=load_hidden, recursive=recursive, depth=depth, types=valid_types\n        )\n\n        loaded_data = []\n        if use_multithreading:\n            loaded_data = parallel_load_data(file_paths, silent_errors=silent_errors, max_concurrency=max_concurrency)\n        else:\n            loaded_data = [parse_text_file_to_data(file_path, silent_errors=silent_errors) for file_path in file_paths]\n\n        valid_data = [x for x in loaded_data if x is not None and isinstance(x, Data)]\n        self.status = valid_data\n        return valid_data\n\n    def as_dataframe(self) -> DataFrame:\n        return DataFrame(self.load_directory())\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "depth": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "depth",
        "value": 0,
        "display_name": "Depth",
        "advanced": false,
        "dynamic": false,
        "info": "Depth to search for files.",
        "title_case": false,
        "type": "int",
        "_input_type": "IntInput"
      },
      "load_hidden": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "load_hidden",
        "value": false,
        "display_name": "Load Hidden",
        "advanced": true,
        "dynamic": false,
        "info": "If true, hidden files will be loaded.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "max_concurrency": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "max_concurrency",
        "value": 2,
        "display_name": "Max Concurrency",
        "advanced": true,
        "dynamic": false,
        "info": "Maximum concurrency for loading files.",
        "title_case": false,
        "type": "int",
        "_input_type": "IntInput"
      },
      "path": {
        "tool_mode": true,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "path",
        "value": ".",
        "display_name": "Path",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Path to the directory to load files from. Defaults to current directory ('.')",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      },
      "recursive": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "recursive",
        "value": false,
        "display_name": "Recursive",
        "advanced": true,
        "dynamic": false,
        "info": "If true, the search will be recursive.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "silent_errors": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "silent_errors",
        "value": false,
        "display_name": "Silent Errors",
        "advanced": true,
        "dynamic": false,
        "info": "If true, errors will not raise an exception.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      },
      "types": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "options": [
          "txt",
          "md",
          "mdx",
          "csv",
          "json",
          "yaml",
          "yml",
          "xml",
          "html",
          "htm",
          "pdf",
          "docx",
          "py",
          "sh",
          "sql",
          "js",
          "ts",
          "tsx"
        ],
        "combobox": false,
        "toggle": false,
        "list": true,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "types",
        "value": [],
        "display_name": "File Types",
        "advanced": false,
        "dynamic": false,
        "info": "File types to load. Select one or more types or leave empty to load all supported types.",
        "title_case": false,
        "type": "str",
        "_input_type": "MultiselectInput"
      },
      "use_multithreading": {
        "tool_mode": false,
        "trace_as_metadata": true,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "use_multithreading",
        "value": false,
        "display_name": "Use Multithreading",
        "advanced": true,
        "dynamic": false,
        "info": "If true, multithreading will be used.",
        "title_case": false,
        "type": "bool",
        "_input_type": "BoolInput"
      }
    },
    "description": "Recursively load files from a directory.",
    "icon": "folder",
    "base_classes": [
      "Data",
      "DataFrame"
    ],
    "display_name": "Directory",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data",
        "display_name": "Data",
        "method": "load_directory",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      },
      {
        "types": [
          "DataFrame"
        ],
        "selected": "DataFrame",
        "name": "dataframe",
        "display_name": "DataFrame",
        "method": "as_dataframe",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "path",
      "types",
      "depth",
      "max_concurrency",
      "load_hidden",
      "recursive",
      "silent_errors",
      "use_multithreading"
    ],
    "beta": false,
    "legacy": false,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  },
  "CSVtoData": {
    "template": {
      "_type": "Component",
      "csv_file": {
        "trace_as_metadata": true,
        "file_path": "",
        "fileTypes": [
          "csv"
        ],
        "temp_file": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "csv_file",
        "value": "",
        "display_name": "CSV File",
        "advanced": false,
        "dynamic": false,
        "info": "Upload a CSV file to convert to a list of Data objects",
        "title_case": false,
        "type": "file",
        "_input_type": "FileInput"
      },
      "code": {
        "type": "code",
        "required": true,
        "placeholder": "",
        "list": false,
        "show": true,
        "multiline": true,
        "value": "import csv\nimport io\nfrom pathlib import Path\n\nfrom langflow.custom import Component\nfrom langflow.io import FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema import Data\n\n\nclass CSVToDataComponent(Component):\n    display_name = \"Load CSV\"\n    description = \"Load a CSV file, CSV from a file path, or a valid CSV string and convert it to a list of Data\"\n    icon = \"file-spreadsheet\"\n    name = \"CSVtoData\"\n    legacy = True\n\n    inputs = [\n        FileInput(\n            name=\"csv_file\",\n            display_name=\"CSV File\",\n            file_types=[\"csv\"],\n            info=\"Upload a CSV file to convert to a list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"csv_path\",\n            display_name=\"CSV File Path\",\n            info=\"Provide the path to the CSV file as pure text\",\n        ),\n        MultilineInput(\n            name=\"csv_string\",\n            display_name=\"CSV String\",\n            info=\"Paste a CSV string directly to convert to a list of Data objects\",\n        ),\n        MessageTextInput(\n            name=\"text_key\",\n            display_name=\"Text Key\",\n            info=\"The key to use for the text column. Defaults to 'text'.\",\n            value=\"text\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"data_list\", display_name=\"Data List\", method=\"load_csv_to_data\"),\n    ]\n\n    def load_csv_to_data(self) -> list[Data]:\n        if sum(bool(field) for field in [self.csv_file, self.csv_path, self.csv_string]) != 1:\n            msg = \"Please provide exactly one of: CSV file, file path, or CSV string.\"\n            raise ValueError(msg)\n\n        csv_data = None\n        try:\n            if self.csv_file:\n                resolved_path = self.resolve_path(self.csv_file)\n                file_path = Path(resolved_path)\n                if file_path.suffix.lower() != \".csv\":\n                    self.status = \"The provided file must be a CSV file.\"\n                else:\n                    with file_path.open(newline=\"\", encoding=\"utf-8\") as csvfile:\n                        csv_data = csvfile.read()\n\n            elif self.csv_path:\n                file_path = Path(self.csv_path)\n                if file_path.suffix.lower() != \".csv\":\n                    self.status = \"The provided file must be a CSV file.\"\n                else:\n                    with file_path.open(newline=\"\", encoding=\"utf-8\") as csvfile:\n                        csv_data = csvfile.read()\n\n            else:\n                csv_data = self.csv_string\n\n            if csv_data:\n                csv_reader = csv.DictReader(io.StringIO(csv_data))\n                result = [Data(data=row, text_key=self.text_key) for row in csv_reader]\n\n                if not result:\n                    self.status = \"The CSV data is empty.\"\n                    return []\n\n                self.status = result\n                return result\n\n        except csv.Error as e:\n            error_message = f\"CSV parsing error: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        except Exception as e:\n            error_message = f\"An error occurred: {e}\"\n            self.status = error_message\n            raise ValueError(error_message) from e\n\n        # An error occurred\n        raise ValueError(self.status)\n",
        "fileTypes": [],
        "file_path": "",
        "password": false,
        "name": "code",
        "advanced": true,
        "dynamic": true,
        "info": "",
        "load_from_db": false,
        "title_case": false
      },
      "csv_path": {
        "tool_mode": false,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "csv_path",
        "value": "",
        "display_name": "CSV File Path",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Provide the path to the CSV file as pure text",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      },
      "csv_string": {
        "tool_mode": false,
        "trace_as_input": true,
        "multiline": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "csv_string",
        "value": "",
        "display_name": "CSV String",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "Paste a CSV string directly to convert to a list of Data objects",
        "title_case": false,
        "copy_field": false,
        "type": "str",
        "_input_type": "MultilineInput"
      },
      "text_key": {
        "tool_mode": false,
        "trace_as_input": true,
        "trace_as_metadata": true,
        "load_from_db": false,
        "list": false,
        "list_add_label": "Add More",
        "required": false,
        "placeholder": "",
        "show": true,
        "name": "text_key",
        "value": "text",
        "display_name": "Text Key",
        "advanced": false,
        "input_types": [
          "Message"
        ],
        "dynamic": false,
        "info": "The key to use for the text column. Defaults to 'text'.",
        "title_case": false,
        "type": "str",
        "_input_type": "MessageTextInput"
      }
    },
    "description": "Load a CSV file, CSV from a file path, or a valid CSV string and convert it to a list of Data",
    "icon": "file-spreadsheet",
    "base_classes": [
      "Data"
    ],
    "display_name": "Load CSV",
    "documentation": "",
    "minimized": false,
    "custom_fields": {},
    "output_types": [],
    "pinned": false,
    "conditional_paths": [],
    "frozen": false,
    "outputs": [
      {
        "types": [
          "Data"
        ],
        "selected": "Data",
        "name": "data_list",
        "display_name": "Data List",
        "method": "load_csv_to_data",
        "value": "__UNDEFINED__",
        "cache": true,
        "allows_loop": false,
        "tool_mode": true
      }
    ],
    "field_order": [
      "csv_file",
      "csv_path",
      "csv_string",
      "text_key"
    ],
    "beta": false,
    "legacy": true,
    "edited": false,
    "metadata": {},
    "tool_mode": false
  }
}